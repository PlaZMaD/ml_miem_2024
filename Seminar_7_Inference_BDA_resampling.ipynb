{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PlaZMaD/ml_miem_2024/blob/main/Seminar_7_Inference_BDA_resampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Семинар 7. Статистический вывод. Байесовский анализ данных.  Методы семплирования\n",
        "\n",
        "\n",
        "(использованы материалы курса [Машинное обучение в Питоне](https://www.hse.ru/edu/courses/450323352))\n",
        "\n",
        "Дополнительная литература:\n",
        "* [Учебник Computer Age Statistical Inference (CASI)](https://web.stanford.edu/~hastie/CASI_files/PDF/casi.pdf). Chapter 3. Bayesian Inference.\n",
        "\n",
        "* [Учебник Bayesian Data Analysis (BDA)](https://users.aalto.fi/~ave/BDA3.pdf) и [курс BDA](https://github.com/avehtari/BDA_course_Aalto) от Aki Vehtari\n"
      ],
      "metadata": {
        "id": "lMDjK3dmmzJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Статистический вывод (inference)"
      ],
      "metadata": {
        "id": "BY3tDQQg7uQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Основы фреквентистских, байесовских (и фишерианских) [выводов](https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D0%B2%D1%8B%D0%B2%D0%BE%D0%B4).\n",
        "\n",
        "Статистический анализ:\n",
        "* Алгоритм\n",
        "  * Среднее значение: $\\bar{x} = \\sum\\limits_{i=1}^n{\\frac{x_i}{n}}$\n",
        "* Вывод\n",
        "  * Стандартная ошибка: $\\widehat{\\mathrm{se}} = \\sqrt{\\frac{\\sum_{i=1}^n{(x_i-\\bar{x})^2}}{n(n-1)}}$\n",
        "\n",
        "\"Вывод\" касается не только точности: говоря в общем, алгоритмы говорят о том, что делает исследователь, в то время как вывод говорит о том, почему он или она это делает.\n",
        "\n",
        "Конечно, $\\widehat{\\mathrm{se}}$ сам по себе является алгоритмом, который может быть (и является) предметом дальнейшего инференциального анализа относительно его точности."
      ],
      "metadata": {
        "id": "CsBzV4Ip7zy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Пример 1. Линейная регрессия\n",
        "\n",
        "Датасет 157 потенциальных доноров почки.\n",
        "`age` - возраст\n",
        "`tot` - некая метрика, соответствующая здоровью почки"
      ],
      "metadata": {
        "id": "BEQVkgpk8tRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортируем необходимые библиотеки\n",
        "import matplotlib.pyplot as plt, seaborn as sns\n",
        "from matplotlib.patches import Patch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from scipy.stats import beta\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import TimeSeriesSplit, KFold, ShuffleSplit, \\\n",
        "  StratifiedKFold, GroupShuffleSplit, GroupKFold, StratifiedShuffleSplit\n",
        "\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "HAzh0VQc8jTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sns.set()\n",
        "# plt.rcParams['figure.figsize'] = [16, 6]"
      ],
      "metadata": {
        "id": "Y32Fq-pn4JaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate https://web.stanford.edu/~hastie/CASI_files/DATA/kidney.txt"
      ],
      "metadata": {
        "id": "6dXsYxxZOu5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузим датасет\n",
        "df = pd.read_csv(\"kidney.txt\", sep=' ')"
      ],
      "metadata": {
        "id": "8O0pTq3F-kR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "U-H2OZbx-uQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "ySVUCumxlyy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Линейное фитирование"
      ],
      "metadata": {
        "id": "OxxJ-suoD2jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ols_result = sm.OLS(df.tot, sm.add_constant(df.age)).fit()\n",
        "print(ols_result.params)"
      ],
      "metadata": {
        "id": "Y_CVPT88CAzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/54540030/to-calculate-the-se-fit-and-resdiual-scale-that-are-the-outputs-from-lm-fu\n",
        "\n",
        "x_pred = np.linspace(20, 80, 7)\n",
        "y_pred = ols_result.predict(sm.add_constant(x_pred))\n",
        "\n",
        "covariance_matrix = ols_result.cov_params()\n",
        "xO = pd.DataFrame({\"Constant\":np.ones(len(x_pred))}).join(pd.DataFrame(x_pred)).values\n",
        "x1 = np.dot(xO, covariance_matrix)\n",
        "y_pred_se = np.sqrt(np.sum(x1 * xO,axis = 1))"
      ],
      "metadata": {
        "id": "-7rNearVqzNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "\n",
        "plt.scatter(df.age, df.tot, c='k', s=2)\n",
        "plt.plot(x_pred, y_pred, c='g')\n",
        "plt.errorbar(x_pred, y_pred, yerr=y_pred_se, linestyle='None', fmt='.r',  capsize=3,  ecolor='k')\n",
        "plt.xlabel('age')\n",
        "plt.ylabel('tot')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "yxdzCeDO-iXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Полиномиальное фитирование"
      ],
      "metadata": {
        "id": "ms5GjlVzD8FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lowess = sm.nonparametric.lowess\n",
        "w = lowess(df.tot, df.age, frac=1./3)\n",
        "# frac - доля данных, используемых  при оценке каждого значения y."
      ],
      "metadata": {
        "id": "9msJDZQmDOPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "\n",
        "plt.scatter(df.age, df.tot, c='k', s=2)\n",
        "plt.plot(w[:,0], w[:,1], c='g')\n",
        "plt.xlabel('age')\n",
        "plt.ylabel('tot')\n",
        "plt.grid();"
      ],
      "metadata": {
        "id": "XRSxV-uUEQdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Не существует формулы, подобной стандартной ошибке, чтобы сделать вывод о точности такой кривой. Вместо этого можно использовать вычислительный механизм статистического вывода - бутстрап. Применение `lowess` к бутстрап-выборке создает бутстрап-репликацию исходного расчета."
      ],
      "metadata": {
        "id": "m-vqv-0YH1Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "\n",
        "plt.scatter(df.age, df.tot, c='k', s=2)\n",
        "\n",
        "for i in range(10):\n",
        "  df2 = df.sample(n=500, replace=True, random_state=i)\n",
        "  w = lowess(df2.tot, df2.age, frac=1./3)\n",
        "  plt.plot(w[:,0], w[:,1])\n",
        "\n",
        "plt.xlabel('age')\n",
        "plt.ylabel('tot')\n",
        "plt.grid();"
      ],
      "metadata": {
        "id": "8QpKvhV6uTvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Изменчивость бутстрап-репликаций определяет точность исходной кривой."
      ],
      "metadata": {
        "id": "7-a0RWXFxrYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Байесовский анализ данных"
      ],
      "metadata": {
        "id": "f30ELvAtnP5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Условные обозначения\n",
        "$\\theta$ - ненаблюдаемые векторные величины или параметры системы\n",
        "\n",
        "y - наблюдаемые данные\n",
        "\n",
        "$\\widetilde{y}$ - неизвестные, но потенциально наблюдаемые величины\n",
        "\n",
        "*Плотность распределения* имеет тот же смысл, что и *распределение*.\n",
        "\n",
        "Обычно мы используем греческие буквы для параметров, строчные латинские буквы для наблюдаемых или наблюдаемых скаляров и векторов (и иногда матриц), и строчные латинские буквы для наблюдаемых или наблюдаемых матриц.\n",
        "\n",
        "$p(\\theta|y)$ или $p(\\widetilde{y}|y)$ - условные вероятности для наблюдаемого значения $y$.\n",
        "\n",
        "$p(\\cdot|\\cdot)$ - условная плотность вероятности\n",
        "\n",
        "$p(\\cdot)$ - частотное (маргинальное) распределение\n",
        "\n",
        "$\\mathrm{Pr}(\\cdot)$ - вероятность события"
      ],
      "metadata": {
        "id": "Fo-HD8eSocGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Правило Байеса\n",
        "\n",
        "Распределение **совместной вероятности** для $\\theta$ и $y$:\n",
        "$$p(\\theta,y) = p(\\theta) p(y|\\theta)$$\n",
        "\n",
        "где:\n",
        "\n",
        "$p(\\theta)$ - предварительное распределение,\n",
        "\n",
        "$p(y|\\theta)$ - распределение выборки (или распределение данных).\n",
        "\n",
        "Правило Байеса определяет **апостериорное распределение**:\n",
        "$$p(\\theta|y) = \\frac{p(\\theta,y)}{p(y)} = \\frac{p(\\theta) p(y|\\theta)}{p(y)}.$$\n",
        "\n",
        "При выбранной вероятностной модели апостериорное распределение $p(\\theta|y)$, рассматриваемое как функция $\\theta$ для фиксированного $y$ есть функция правдоподобия."
      ],
      "metadata": {
        "id": "MIPveefSpCD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Некоторые широкораспространённые распределения (учебник BDA, Приложение A)\n",
        "\n",
        "### Непрерывные:\n",
        "\n",
        "| Распределение | Обозначения <img width=105/> | Параметры <img width=80/> |\n",
        "| ----------- | --------- | ----------- |\n",
        "| **Uniform** | $\\theta \\sim \\mathrm{U}(\\alpha, \\beta)$<br />$p(\\theta) = \\mathrm{U}(\\theta|\\alpha,\\beta)$ | boundaries $\\alpha, \\beta$ with $\\beta > \\alpha$ |\n",
        "| **Normal**<br />**(Gaussian)** | $\\theta \\sim \\mathrm{N}(\\mu, \\sigma^2)$<br />$p(\\theta) = \\mathrm{N}(\\theta|\\mu,\\sigma^2)$ | location $\\mu$ and scale $\\sigma > 0$ |\n",
        "| **Lognormal** | $\\theta \\sim \\mathrm{lognorm}(\\mu, \\sigma^2)$<br />$p(\\theta) = \\mathrm{lognorm}(\\theta|\\mu,\\sigma^2)$ | location $\\mu$ and log-scale $\\sigma > 0$ |\n",
        "| **Multivariate normal** | $\\theta \\sim \\mathrm{N}(\\mu, \\Sigma)$<br />$p(\\theta) = \\mathrm{N}(\\theta|\\mu,\\Sigma)$<br />(implicit dimension $d$) | symmetric, pos. definite<br />$d\\times d$ variance matrix $\\Sigma$ |\n",
        "| **Gamma** | $\\theta \\sim \\mathrm{Gamma}(\\alpha, \\beta)$<br />$p(\\theta) = \\mathrm{Gamma}(\\theta|\\alpha, \\beta)$ | shape $\\alpha > 0$ and inverse scale $\\beta > 0$ |\n",
        "| **Chi-square** | $\\theta \\sim \\chi_\\nu^2$<br />$p(\\theta) = \\chi_\\nu^2(\\theta)$ | degrees of freedom $\\nu > 0$ |\n",
        "| **t**<br />**(Student-t)** | $\\theta \\sim \\mathrm{t}_\\nu(\\mu,\\sigma^2)$<br />$p(\\theta) = \\mathrm{t}_\\nu(\\theta|\\mu,\\sigma^2)$ | degrees of freedom $\\nu > 0$<br />location $\\mu$ and scale $\\sigma > 0$ |\n",
        "| **Beta** | $\\theta \\sim \\mathrm{Beta}(\\alpha, \\beta)$<br />$p(\\theta) = \\mathrm{Beta}(\\theta|\\alpha, \\beta)$ | 'prior sample sizes' $\\alpha > 0$ and $\\beta > 0$ |\n",
        "\n",
        "### Дискретные:\n",
        "\n",
        "| Распределение | Обозначения <img width=145/> | Параметры <img width=80/> |\n",
        "| ----------- | --------- | ----------- |\n",
        "| **Poisson** | $\\theta \\sim \\mathrm{Poisson}(\\lambda)$<br />$p(\\theta) = \\mathrm{Poisson}(\\theta|\\lambda)$ | 'rate' $\\lambda > 0$ |\n",
        "| **Binomial** | $\\theta \\sim \\mathrm{Bin}(n, p)$<br />$p(\\theta) = \\mathrm{Bin}(\\theta|n,p)$ | 'sample size' $n$ (positive integer)<br />'probability' $p\\in[0,1]$ |\n",
        "| **Bernoulli**<br />(Binomial with n=1) | $\\theta \\sim \\mathrm{Bern}(p)$<br />$p(\\theta) = \\mathrm{Bern}(\\theta|p)$ | 'probability' $p\\in[0,1]$ |\n",
        "| **Multinomial** | $\\theta \\sim \\mathrm{Multin}(n; p_1,...,p_k)$<br />$p(\\theta) = \\mathrm{Multin}(\\theta|n; p_1,...,p_k)$ | 'sample size' $n$ (positive integer)<br />'probabilities' $p_j\\in[0,1]$<br />$\\sum_{j=1}^k p_j = 1$ |"
      ],
      "metadata": {
        "id": "-mkhBub0pwed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Пример 1. Анализ с использованием равномерного априорного распределения\n",
        "\n",
        "**Вероятность рождения девочки при предлежании плаценты у матери** (учебник BDA, стр. 37):\n",
        "\n",
        "Исследование рожениц с предлежанием плаценты в Германии показало, что из `980` рождённых `437` были девочками. Насколько это подтверждает утверждение, что доля девочек, рождённых у матерей с предлежанием плаценты меньше, чем `0.485` = доли женщин в общей популяции?\n",
        "\n",
        "Всего наблюдалось `437` девочек и `543` мальчика. Вычислите и постройте график апостериорного распределения доли девочек $\\theta$, используя равномерное априорное распределение $\\theta$."
      ],
      "metadata": {
        "id": "KKC-U4_ls3Ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Известно, что для равномерного априорного распределения [сопряжённым](https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D0%BF%D1%80%D1%8F%D0%B6%D1%91%D0%BD%D0%BD%D0%BE%D0%B5_%D0%B0%D0%BF%D1%80%D0%B8%D0%BE%D1%80%D0%BD%D0%BE%D0%B5_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5) будет Бета-распределение. Поэтому апостериорная вероятность будет `Beta(437+1, 543+1)`."
      ],
      "metadata": {
        "id": "N8p6VituxZdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "?beta"
      ],
      "metadata": {
        "id": "4FD_ZTDMpZc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dist = beta(438, 544)"
      ],
      "metadata": {
        "id": "CGht_uc3y1Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте пройдёмся по значениям вокруг искомой вероятности:"
      ],
      "metadata": {
        "id": "V-WJI0wny9TD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(0.36, 0.54, 80)"
      ],
      "metadata": {
        "id": "ouPpH6s1zZPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "И найдём плотность вероятности для `Beta(438, 544)`:\n",
        "\n"
      ],
      "metadata": {
        "id": "A7goBmxfzadz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdz = dist.pdf(x)"
      ],
      "metadata": {
        "id": "UiRpCAcaznRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cb08ZBXQqVPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Построим соответствующее распределение:"
      ],
      "metadata": {
        "id": "B1Kr_BnczyFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Равномерное априорное распределение -> Апостериорное Beta(438,544)-распределение')\n",
        "fig, ax = plt.subplots(figsize=(12,6))\n",
        "plt.plot(x, pdz)\n",
        "\n",
        "plt.annotate(r'$p(\\theta|y,n)$', (x[35] - 0.005, pdz[35]), ha='right')\n",
        "\n",
        "plt.axvline(0.485, color='C1')\n",
        "plt.annotate('Средняя доля женщин \\nв популяции', (0.485 + 0.005, 14), ha='left')\n",
        "\n",
        "# вычислим точки, попавшие в интервал между 2.5% и 97.5%\n",
        "x_95_idx = (x > dist.ppf(0.025)) & (x < dist.ppf(0.975))\n",
        "plt.fill_between(x[x_95_idx], pdz[x_95_idx], color='gray')\n",
        "plt.text(dist.median(), 8, \"95%\", horizontalalignment='center')\n",
        "\n",
        "\n",
        "plt.xlabel(r'$\\theta$')\n",
        "ax.axes.get_yaxis().set_visible(False)"
      ],
      "metadata": {
        "id": "H4Es1-EfrQ6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Пример 2. Иллюстрация влияния априорной информации в биномиальной модели\n",
        "\n",
        "Проиллюстрируйте влияние априорной информации и сравните апостериорные распределения с различными значениями параметров для бета-распределения. Используйте данные из Примера 1."
      ],
      "metadata": {
        "id": "JVMrrxDG3iLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(0.375, 0.525, 150)\n",
        "\n",
        "# апостериорное распределение для данных (437,543) и равномерное априорное распределение Beta(1,1)\n",
        "au = 438\n",
        "bu = 544\n",
        "# подсчитаем плотности вероятности (pdf)\n",
        "pdu = beta.pdf(x, au, bu)\n",
        "\n",
        "# сравним 3 случая различных априорных распределений\n",
        "# Beta(0.485*n, (1-0.485)*n), для n = 2, 20, 200\n",
        "ap = np.array([0.485 * (2*10**i) for i in range(3)])\n",
        "bp = np.array([(1-0.485) * (2*10**i) for i in range(3)])\n",
        "# corresponding posteriors with data (437,543)\n",
        "ai = 437 + ap\n",
        "bi = 543 + bp\n",
        "# подсчитаем априорные и постериорные pdf-распределения\n",
        "pdp = beta.pdf(x, ap[:,np.newaxis], bp[:,np.newaxis])\n",
        "pdi = beta.pdf(x, ai[:,np.newaxis], bi[:,np.newaxis])"
      ],
      "metadata": {
        "id": "SbfA_1614XtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Построим эти распределения:"
      ],
      "metadata": {
        "id": "yLUxQmBU595I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot 3 subplots\n",
        "fig, axes = plt.subplots(\n",
        "    nrows=3, ncols=1, sharex=True, sharey=True, figsize=(8, 12))\n",
        "# show only x-axis\n",
        "# plot_tools.modify_axes.only_x(axes)\n",
        "# manually adjust spacing\n",
        "fig.subplots_adjust(hspace=0.4)\n",
        "\n",
        "# 3 subplots\n",
        "for i, ax in enumerate(axes):\n",
        "    # plot three precalculated densities\n",
        "    post1, = ax.plot(x, pdu, color='C1', linewidth=5)\n",
        "    prior, = ax.plot(x, pdp[i], 'k:')\n",
        "    post2, = ax.plot(x, pdi[i], color='k', dashes=(6, 8))\n",
        "    # add vertical line\n",
        "    known = ax.axvline(0.485, color='C0')\n",
        "    # set the title for this subplot\n",
        "    ax.set_title(\n",
        "        r'$\\alpha/(\\alpha+\\beta) = 0.485,\\quad \\alpha+\\beta = {}$'\n",
        "        .format(2*10**i)\n",
        "    )\n",
        "# limit x-axis\n",
        "axes[0].autoscale(axis='x', tight=True)\n",
        "axes[0].set_ylim((0,30))\n",
        "# add legend to the last subplot\n",
        "axes[-1].legend(\n",
        "    (post1, prior, post2, known),\n",
        "    ( 'апостериорное с равномерным априорным',\n",
        "      'информативное априорное',\n",
        "      'апостериорное c информативным априорным',\n",
        "     r'известная доля женщин в популяции ($\\theta=0.485$)'),\n",
        "    loc='upper center',\n",
        "    bbox_to_anchor=(0.5, -0.2)\n",
        ");"
      ],
      "metadata": {
        "id": "gRbEF6cy5hfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Методы семплирования\n",
        "Мы рассмотрим два метода семлирования (получения повторной выборки), которые вы можете использовать для оценки качества ваших моделей машинного обучения:\n",
        "* Кросс-валидация\n",
        "* Бутстрап"
      ],
      "metadata": {
        "id": "nbvDIaJaqqYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_url = 'https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv'\n",
        "df = pd.read_csv(csv_url)\n",
        "df.columns=['psgr','srv','pcls','name','sex','age','sibsp','parch','tkt','fare','cab','emb']\n",
        "df.sex = 1*(df.sex=='male')"
      ],
      "metadata": {
        "id": "gzQKNIUj2AvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df.drop(['cab', 'tkt', 'name'], axis=1)\n",
        "\n",
        "df_filtered[\"emb_is_S\"] = (df_filtered[\"emb\"] == \"S\").astype(int)\n",
        "df_filtered[\"emb_is_C\"] = (df_filtered[\"emb\"] == \"C\").astype(int)\n",
        "\n",
        "df_filtered = df_filtered.drop([\"emb\"], axis=1)\n",
        "\n",
        "median_age = df_filtered[\"age\"].median()\n",
        "print(\"Filling NA values with age\", median_age)\n",
        "df_filtered = df_filtered.fillna(median_age)\n",
        "\n",
        "fare_max = df_filtered['fare'].quantile(0.95)\n",
        "df_filtered.loc[df_filtered['fare'] > fare_max, \"fare\"] = fare_max\n",
        "\n",
        "sibsp_max = df_filtered['sibsp'].quantile(0.95)\n",
        "df_filtered.loc[df_filtered['sibsp'] > sibsp_max, \"sibsp\"] = sibsp_max"
      ],
      "metadata": {
        "id": "eo6g3ML-2NGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered.head()"
      ],
      "metadata": {
        "id": "IKpM4KZy2X2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_filtered.drop([\"srv\"], axis=1), df_filtered[\"srv\"])\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors=3)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict_proba(X_test)[:, 1]\n",
        "score = roc_auc_score(y_test, y_pred)\n",
        "print('ROC AUC', score)"
      ],
      "metadata": {
        "id": "6rWYSnZl29FH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы получили показатель ROC AUC для нашего классификатора. Однако если мы повторим запуск этой ячейки несколько раз, то получим другие результаты.\n",
        "Давайте подтвердим это:"
      ],
      "metadata": {
        "id": "8fabbZ2h3eiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set()\n",
        "plt.rcParams['figure.figsize'] = [16, 6]\n",
        "\n",
        "scores = []\n",
        "for i in range(250):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        df_filtered.drop([\"srv\"], axis=1), df_filtered[\"srv\"], test_size=0.3 )\n",
        "\n",
        "    model = KNeighborsClassifier(n_neighbors=3)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict_proba(X_test)[:, 1]\n",
        "    scores.append(roc_auc_score(y_test, y_pred))\n",
        "\n",
        "plt.figure()\n",
        "sns.boxplot(x=scores)\n",
        "plt.title('Распределение метрики ROC AUC')\n",
        "plt.xlabel('ROC AUC')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cR2zPtta3gHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "sns.histplot(scores, kde=True)\n",
        "plt.title('Распределение метрики ROC AUC')\n",
        "plt.xlabel('ROC AUC')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SHmK_Pxd3_Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценки метрики могут отличаться более, чем на 0.1 по абсолютной величине между разными прогонами!"
      ],
      "metadata": {
        "id": "utvIavdt47PG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Производительность модели в значительной степени зависит от того, как мы выбрали обучающую и тестовую выборки.\n",
        "\n",
        "Поэтому мы не можем использовать разделение на обучающую и тестовую выборки для получения надежных оценок производительности модели. Это также означает, что мы не можем использовать их для поиска лучших гиперпараметров (например, параметра $k$ для KNN)."
      ],
      "metadata": {
        "id": "DJyNLTBY5EVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы хотим знать, насколько хороша наша модель **в целом**.  Мы хотели бы получить метод, который не зависит от способа разбиения данных. Такой метод существует, и он называется кросс-валидацией."
      ],
      "metadata": {
        "id": "QFjtxK7E5lDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Кросс-валидация"
      ],
      "metadata": {
        "id": "sD4BZ8jv5poH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Идея кросс-валидации:\n",
        "1. Выполнить несколько разбиений.\n",
        "2. Для каждого разбиения подогнать модель к обучающей выборке, предсказать и вычислить оценку (например, точность) на тестовой выборке.\n",
        "3. Усреднить результаты, получить доверительные интервалы.\n",
        "\n",
        "Существует множество способов выполнения первого шага. Главное, чтобы каждое наблюдение появилось хотя бы в одной из подвыборок.\n",
        "\n",
        "Иногда можно сделать столько разбиений, сколько у вас наблюдений ($N$). Но это очень медленно, потому что вам придется подгонять $N$ моделей. Поэтому вместо этого вы можете сделать несколько непересекающихся разбиений с $k < N$ наблюдений в каждом, чтобы подогнать меньше моделей и получить похожие результаты. Мы попробуем эти и другие методы ниже.\n",
        "\n",
        "Кросс-валидация может использоваться для:\n",
        "* Получения надежной оценки ошибки в тестовой выборке.\n",
        "* Сравнения моделей по производительности.\n",
        "* Нахождения наилучших значений для гиперпараметров.\n"
      ],
      "metadata": {
        "id": "lhv3KeMd5sfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Отсюда: https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html\n",
        "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
        "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
        "\n",
        "    # Generate the training/testing visualizations for each CV split\n",
        "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
        "        # Fill in indices with the training/test groups\n",
        "        indices = np.array([np.nan] * len(X))\n",
        "        indices[tt] = 1\n",
        "        indices[tr] = 0\n",
        "\n",
        "        # Visualize the results\n",
        "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
        "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
        "                   vmin=-.2, vmax=1.2)\n",
        "\n",
        "    # Plot the data classes and groups at the end\n",
        "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
        "               c=y, marker='_', lw=lw, cmap=cmap_data)\n",
        "\n",
        "    ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n",
        "               c=group, marker='_', lw=lw, cmap=cmap_data)\n",
        "\n",
        "    # Formatting\n",
        "    yticklabels = list(range(n_splits)) + ['class', 'group']\n",
        "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
        "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
        "           ylim=[n_splits+2.2, -.2], xlim=[0, 100])\n",
        "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.random.seed(0)\n",
        "cmap_data = plt.cm.Paired\n",
        "cmap_cv = plt.cm.coolwarm\n",
        "n_splits = 4"
      ],
      "metadata": {
        "id": "iior7XTd6Vq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_bars(bars, y=0.5, vmin=-.2, vmax=1.2, label=None):\n",
        "    ax = plt.gca()\n",
        "    ax.scatter(range(len(bars)),  [y] * len(bars), c=bars, marker='_',\n",
        "               lw=50, label=label, cmap=cmap_cv, vmin=vmin, vmax=vmax)"
      ],
      "metadata": {
        "id": "pbFYPshN6YPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Визуализация разделения на train и test\n",
        "\n",
        "Прежде всего, давайте посмотрим на наше разделение на тренировочную и тестовую выборки."
      ],
      "metadata": {
        "id": "qN60zepK6lN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx, test_idx = train_test_split(df_filtered.index, test_size=0.3, shuffle=False)\n",
        "idx_labels = np.array([(idx in train_idx) for idx in df_filtered.index])\n",
        "\n",
        "train_idx, test_idx = train_test_split(df_filtered.index, test_size=0.3)\n",
        "idx_labels_shuffled = np.array([(idx in train_idx) for idx in df_filtered.index])\n",
        "\n",
        "plt.figure()\n",
        "draw_bars(idx_labels, y=0.5)\n",
        "draw_bars(idx_labels_shuffled, y=1.5)\n",
        "plt.xlabel('Observation index')\n",
        "plt.yticks([0.5, 1.5], ['Train-test split without shuffling', 'Train-test split shuffled'])\n",
        "plt.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n",
        "              ['Training set', 'Testing set'], loc=(1.02, .8))\n",
        "\n",
        "plt.ylim([0, 2])\n",
        "plt.title('How train-test split distributes observations')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4PgTCOlX6thw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Fold Кросс-валидация"
      ],
      "metadata": {
        "id": "ZelPVOEr7AXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Идея: разделить набор данных на $K$ **непересекающихся** групп. Каждая из $K$ групп используется в качестве валидационного набора один раз, а остальные $K-1$ групп используются в качестве обучающего набора.\n",
        "\n",
        "По умолчанию перетасовка данных не производится, но обычно ее полезно сделать."
      ],
      "metadata": {
        "id": "ajtYYalX7LHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cv_splits(cv, index, title, y=None, groups=None):\n",
        "    plt.figure()\n",
        "\n",
        "    y_ticks_pos = []\n",
        "    y_ticks = []\n",
        "    for i, (train_idx, test_idx) in enumerate(cv.split(index, y=y, groups=groups)):\n",
        "        idx_labels = np.array([(idx in train_idx) for idx in index])\n",
        "        draw_bars(idx_labels, y=0.5+i)\n",
        "        y_ticks_pos.append(0.5+i)\n",
        "        y_ticks.append(f'Fold {i}')\n",
        "\n",
        "    if y is not None:\n",
        "        i += 1\n",
        "        draw_bars(y, y=0.5+i, vmin=0.5, vmax=0.8)\n",
        "        y_ticks_pos.append(0.5+i)\n",
        "        y_ticks.append(f'Class')\n",
        "\n",
        "    plt.xlabel('Observation index')\n",
        "    plt.yticks(y_ticks_pos, y_ticks)\n",
        "    plt.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n",
        "                ['Training set', 'Testing set'], loc=(1.02, .8))\n",
        "\n",
        "    plt.ylim([0, i+1])\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ufLPfAXL7NnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = KFold(n_splits, shuffle=False)\n",
        "plot_cv_splits(cv, df_filtered.index, 'How K-Fold distributes observations')"
      ],
      "metadata": {
        "id": "86yE1YAl7RoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Fold великолепен, но давайте посмотрим, как он справляется с классами \"Титаника\". Я сортирую цели так, чтобы график был более наглядным."
      ],
      "metadata": {
        "id": "ftkCkq797lPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_cv_splits(cv, df_filtered.index, 'How K-Fold handles an imbalanced dataset', y=sorted(df_filtered['srv']))"
      ],
      "metadata": {
        "id": "V-7chtZm7mX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Это не очень хорошо: в фолдах будет разное распределение классов. Мы хотим сохранить распределение классов, чтобы наши модели могли научиться чему-то действительно полезному."
      ],
      "metadata": {
        "id": "3PvZBk607x_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Стратифицированный K-fold** гарантирует, что исходное распределение классов сохраняется в каждом фолде."
      ],
      "metadata": {
        "id": "2Yv6ThpW7y9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = StratifiedKFold(n_splits)\n",
        "plot_cv_splits(cv, df_filtered.index, 'How Startified K-Fold handles an imbalanced dataset', y=sorted(df_filtered['srv']))"
      ],
      "metadata": {
        "id": "oEB2rTy578RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bootstrap"
      ],
      "metadata": {
        "id": "Eg8d-jv78UbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Бутстреп - это общая статистическая техника, использующая **выборку с заменой** для получения оценок статистических данных, таких как среднее и дисперсия, вычисления доверительных интервалов и многого другого. Он работает **независимо от базового распределения**, поэтому подходит для негауссовых вещей. Представьте себе, как это здорово.\n",
        "\n",
        "Идея бутстрапа: использовать множество (тысячи) малых выборок для оценки величин всей популяции.\n",
        "\n",
        "Алгоритм получения бутстреп-оценки для среднего значения:\n",
        "1. Выберите количество бутстреп-выборок для выполнения.\n",
        "2. Выберите размер выборки.\n",
        "3. Для каждой бутстрап-выборки постройте выборку с заменой с выбранным размером.\n",
        "4. Вычислите среднее значение выборки и сохраните его.\n",
        "5. Вычислите среднее значение вычисленных выборочных средних."
      ],
      "metadata": {
        "id": "xXFadBaa8bP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "column = 'age'\n",
        "column_sample = df_filtered[column][::10].values\n",
        "print('Length of source', len(df_filtered[column]))\n",
        "print('Length of sample', len(column_sample))\n",
        "sns.distplot(df_filtered[column], label=column)\n",
        "sns.distplot(column_sample, label='Sample')\n",
        "plt.legend()\n",
        "plt.title('Distributions of fare and sample of fare')\n",
        "plt.show()\n",
        "print('Source values', len(df_filtered[column]))\n",
        "print('Sample values', len(column_sample))\n",
        "\n",
        "print('Source mean', df_filtered[column].mean())\n",
        "print('Sample mean', column_sample.mean())"
      ],
      "metadata": {
        "id": "LHk-dNfz8eny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы заинтересованы в получении оценки среднего возраста и доверительного интервала для него."
      ],
      "metadata": {
        "id": "7PCbaYcL8iGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = len(column_sample)//2\n",
        "sample = np.random.choice(column_sample, size=sample_size, replace=True)"
      ],
      "metadata": {
        "id": "2DG9dBJz8kcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iterations = 1000\n",
        "sample_size = len(column_sample)//2\n",
        "means = []\n",
        "for i in range(n_iterations):\n",
        "    sample = np.random.choice(column_sample, size=sample_size, replace=True)\n",
        "    means.append(np.mean(sample))\n",
        "means = np.array(means)\n",
        "print('Bootstrap mean', np.mean(means))"
      ],
      "metadata": {
        "id": "xWedNvut8mM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для получения доверительных интервалов мы можем использовать **метод бутстреп-процентилей** выборочных средних.\n",
        "\n",
        "Пусть $\\theta$ - это бутстреп-средние выборочной совокупности.\n",
        "\n",
        "Для некоторой ширины доверительного интервала $p$, например, $95\\%$:\n",
        "1. Вычислите $\\alpha$ как $1 - p$.\n",
        "2. Получите нижний перцентиль $\\alpha / 2$.\n",
        "3. Получите верхний перцентиль $1 - \\alpha/2$\n",
        "4. Получите доверительный интервал: $[ процентиль(\\theta, \\alpha / 2), процентиль(\\theta, 1- \\alpha / 2) ]$"
      ],
      "metadata": {
        "id": "ZvlY0wdt8t0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0.95\n",
        "alpha = 1 - p\n",
        "lower = np.percentile(means, (alpha/2)*100)\n",
        "upper = np.percentile(means, (1-alpha/2)*100)\n",
        "print(f'{round(p*100)}% confidence interval for the bootstrap mean: ({lower:2f}, {upper:2f})')"
      ],
      "metadata": {
        "id": "7HfNUO9H8vwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот метод является самым простым и, скорее всего, [самым худшим](https://stats.stackexchange.com/questions/355781/is-it-true-that-the-percentile-bootstrap-should-never-be-used). Известно, что он дает плохие результаты, когда распределение выборочной статистики перекошено.\n",
        "\n",
        "Менее предвзятым методом является **эмпирический бутстрап**. В нем для оценки доверительного интервала используется отклонение выборочных средних от среднего выборочного значения.\n",
        "\n",
        "1. Вычислите отклонения выборочных средних от среднего значения $\\delta = \\{\\theta_0 - \\mathop{\\mathbb{E}}[\\theta], \\theta_1 - \\mathop{\\mathbb{E}}[\\theta], \\dots \\}$.\n",
        "2. Получите доверительный интервал: $[ \\mathop{\\mathbb{E}}[\\theta] - процентиль(\\delta, 1 - \\alpha / 2), \\mathop{\\mathbb{E}}[\\theta] - процентиль(\\delta, \\alpha / 2) ]$"
      ],
      "metadata": {
        "id": "F-a2wQHk85o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deviations = means - np.mean(means)\n",
        "lower = np.mean(means) - np.percentile(deviations, (1-alpha/2)*100)\n",
        "upper = np.mean(means) - np.percentile(deviations, (alpha/2)*100)\n",
        "print(f'Empirical bootstrap {round(p*100)}% confidence interval for the bootstrap mean: ({lower:2f}, {upper:2f})')"
      ],
      "metadata": {
        "id": "Ubp6v_Sq86yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Получение доверительного интервала для точности классификатора с помощью бутстрепа"
      ],
      "metadata": {
        "id": "qrEg-EAB89ev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Представьте, что существует некоторая неизвестная совокупность погрешностей нашего классификатора. Мы хотим получить среднее значение этой совокупности. У нас есть \"образцы\" наших точностей: результаты подгонки классификатора к некоторым данным и вычисления точности на проверочном множестве."
      ],
      "metadata": {
        "id": "B_k5kl9-9BvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_filtered.drop([\"srv\"], axis=1), df_filtered[\"srv\"], test_size=0.3)\n",
        "\n",
        "X_train = X_train.values\n",
        "y_train = y_train.values\n",
        "\n",
        "pipe = Pipeline([('scale', StandardScaler()),\n",
        "                ('clf', KNeighborsClassifier(n_jobs=-1,))])"
      ],
      "metadata": {
        "id": "eKlPexCc9Fpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.utils import resample\n",
        "\n",
        "n_iterations = 100\n",
        "n_size = len(X_train)//2\n",
        "model = pipe\n",
        "\n",
        "accuracies = []\n",
        "for i in tqdm(range(n_iterations)):\n",
        "\ttrain_idx = resample(range(len(X_train)), n_samples=n_size)\n",
        "\tval_idx = np.array([i for i in range(len(X_train)) if i not in train_idx])\n",
        "\n",
        "\tmodel.fit(X_train[train_idx], y_train[train_idx])\n",
        "\t# evaluate model\n",
        "\tpredictions = model.predict(X_train[val_idx])\n",
        "\tscore = accuracy_score(y_train[val_idx], predictions)\n",
        "\taccuracies.append(score)\n",
        "\n",
        "sns.displot(accuracies)\n",
        "plt.title('Accuracies on bootstrap samples')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4CZiVNRP9IvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = 0.95\n",
        "alpha = 1 - p\n",
        "lower = np.percentile(accuracies, (alpha/2)*100)\n",
        "upper = np.percentile(accuracies, (1-alpha/2)*100)\n",
        "print(f'Accuracy according to percentile bootstrap: ({lower:2f}, {upper:2f})')"
      ],
      "metadata": {
        "id": "Aw2yFHEf9Mwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'True accuracy on test set: {accuracy:2f}')"
      ],
      "metadata": {
        "id": "pSTunWAP9NLC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}