{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WQccmM8rxQ-"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/MLDM-2022/blob/master/12-architectures/TL_AE_HW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-20T12:19:29.305598Z",
          "iopub.status.busy": "2022-11-20T12:19:29.304997Z",
          "iopub.status.idle": "2022-11-20T12:19:31.757563Z",
          "shell.execute_reply": "2022-11-20T12:19:31.756141Z",
          "shell.execute_reply.started": "2022-11-20T12:19:29.305481Z"
        },
        "id": "z84mnv1t_425"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from os import listdir, makedirs, getcwd, remove\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-20T12:19:31.760714Z",
          "iopub.status.busy": "2022-11-20T12:19:31.759296Z",
          "iopub.status.idle": "2022-11-20T12:19:31.766464Z",
          "shell.execute_reply": "2022-11-20T12:19:31.764974Z",
          "shell.execute_reply.started": "2022-11-20T12:19:31.760670Z"
        },
        "id": "fKajd0ZU_426"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1337)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "f5af2eca-5b02-4d89-a36d-8ca330851ac3",
        "_uuid": "11db94b40434802ac10d5ed76e21d33b9ff6befe",
        "id": "FwTpmkJO_422"
      },
      "source": [
        "# Dog Breed Identification\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IykQuyPyDlXs"
      },
      "source": [
        "Download the dataset from [Dog Breed Identification\n",
        " Competition](https://www.kaggle.com/competitions/dog-breed-identification/data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43tf4uPHAa2O"
      },
      "outputs": [],
      "source": [
        "# !mkdir ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCEyHF13AMzx"
      },
      "outputs": [],
      "source": [
        "# !kaggle competitions download -c dog-breed-identification\n",
        "!gdown 1gnWiIwfHGjU4HFElAcrD1pOGP1st8tQI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5gUVsn-A-6U"
      },
      "outputs": [],
      "source": [
        "!unzip dog-breed-identification.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIsz6XZv_429"
      },
      "source": [
        "Let's use 64 most frequent breeds to simplify the task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-20T12:19:35.403850Z",
          "iopub.status.busy": "2022-11-20T12:19:35.403431Z",
          "iopub.status.idle": "2022-11-20T12:19:36.485851Z",
          "shell.execute_reply": "2022-11-20T12:19:36.484579Z",
          "shell.execute_reply.started": "2022-11-20T12:19:35.403818Z"
        },
        "id": "owX4xvVg_429"
      },
      "outputs": [],
      "source": [
        "INPUT_SIZE = 224\n",
        "NUM_CLASSES = 64\n",
        "data_dir = '/content/data/'\n",
        "labels = pd.read_csv(join(data_dir, 'labels.csv'))\n",
        "sample_submission = pd.read_csv(join(data_dir, 'sample_submission.csv'))\n",
        "print(len(listdir(join(data_dir, 'train'))), len(labels))\n",
        "print(len(listdir(join(data_dir, 'test'))), len(sample_submission))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-20T12:19:38.418926Z",
          "iopub.status.busy": "2022-11-20T12:19:38.418491Z",
          "iopub.status.idle": "2022-11-20T12:19:38.480493Z",
          "shell.execute_reply": "2022-11-20T12:19:38.479321Z",
          "shell.execute_reply.started": "2022-11-20T12:19:38.418889Z"
        },
        "id": "nmDLzy33_429"
      },
      "outputs": [],
      "source": [
        "selected_breed_list = list(labels.groupby('breed').count().sort_values(by='id', ascending=False).head(NUM_CLASSES).index)\n",
        "labels = labels[labels['breed'].isin(selected_breed_list)]\n",
        "labels['target'] = 1\n",
        "labels['rank'] = labels.groupby('breed').rank()['id']\n",
        "labels_pivot = labels.pivot('id', 'breed', 'target').reset_index().fillna(0)\n",
        "\n",
        "train = labels_pivot.sample(frac=0.8)\n",
        "valid = labels_pivot[~labels_pivot['id'].isin(train['id'])]\n",
        "print(train.shape, valid.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbjdVxCND9Cu"
      },
      "source": [
        "Custom dataset is going to be useful for our needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-20T12:21:25.372206Z",
          "iopub.status.busy": "2022-11-20T12:21:25.371623Z",
          "iopub.status.idle": "2022-11-20T12:21:25.385456Z",
          "shell.execute_reply": "2022-11-20T12:21:25.384555Z",
          "shell.execute_reply.started": "2022-11-20T12:21:25.372151Z"
        },
        "id": "YeBIQ3Y6_42-"
      },
      "outputs": [],
      "source": [
        "class DogsDataset(Dataset):\n",
        "    def __init__(self, labels, root_dir, subset=False, transform=None):\n",
        "        self.labels = labels\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = '{}.jpg'.format(self.labels.iloc[idx, 0])\n",
        "        fullname = join(self.root_dir, img_name)\n",
        "        image = Image.open(fullname)\n",
        "        labels = self.labels.iloc[idx, 1:].to_numpy().astype('float')\n",
        "        labels = np.argmax(labels)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return [image, labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-20T12:21:25.639926Z",
          "iopub.status.busy": "2022-11-20T12:21:25.639454Z",
          "iopub.status.idle": "2022-11-20T12:21:25.648535Z",
          "shell.execute_reply": "2022-11-20T12:21:25.647318Z",
          "shell.execute_reply.started": "2022-11-20T12:21:25.639888Z"
        },
        "id": "Pi1WBa83_42-"
      },
      "outputs": [],
      "source": [
        "normalize = transforms.Normalize(\n",
        "   mean=[0.485, 0.456, 0.406],\n",
        "   std=[0.229, 0.224, 0.225]\n",
        ")\n",
        "ds_trans = transforms.Compose([transforms.Resize(224),\n",
        "                               transforms.CenterCrop(224),\n",
        "                               transforms.ToTensor(),\n",
        "                               normalize])\n",
        "train_ds = DogsDataset(train, data_dir + 'train/', transform=ds_trans)\n",
        "valid_ds = DogsDataset(valid, data_dir + 'train/', transform=ds_trans)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=4, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-20T12:21:25.847758Z",
          "iopub.status.busy": "2022-11-20T12:21:25.847349Z",
          "iopub.status.idle": "2022-11-20T12:21:25.854367Z",
          "shell.execute_reply": "2022-11-20T12:21:25.853367Z",
          "shell.execute_reply.started": "2022-11-20T12:21:25.847725Z"
        },
        "id": "rsZF3ehw_42-"
      },
      "outputs": [],
      "source": [
        "def imshow(axis, inp):\n",
        "    \"\"\"Denormalize and show\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    axis.imshow(inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-20T12:21:27.116968Z",
          "iopub.status.busy": "2022-11-20T12:21:27.116556Z",
          "iopub.status.idle": "2022-11-20T12:21:48.607590Z",
          "shell.execute_reply": "2022-11-20T12:21:48.606428Z",
          "shell.execute_reply.started": "2022-11-20T12:21:27.116931Z"
        },
        "id": "YaOJt29S_42_"
      },
      "outputs": [],
      "source": [
        "img, label = next(iter(train_dl))\n",
        "print(img.size(), label.size())\n",
        "fig = plt.figure(1, figsize=(16, 4))\n",
        "grid = ImageGrid(fig, 111, nrows_ncols=(1, 4), axes_pad=0.05)\n",
        "for i in range(img.size()[0]):\n",
        "    ax = grid[i]\n",
        "    imshow(ax, img[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyQlkHyl_42_"
      },
      "source": [
        "# Task 1: Transfer Learning (2 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icwJfGhzEWGV"
      },
      "source": [
        "Pick up some pretrained model, e.g. resnet 50 and tune it for our needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-11-20T12:22:42.969917Z",
          "iopub.status.busy": "2022-11-20T12:22:42.969487Z",
          "iopub.status.idle": "2022-11-20T12:23:03.494546Z",
          "shell.execute_reply": "2022-11-20T12:23:03.492219Z",
          "shell.execute_reply.started": "2022-11-20T12:22:42.969876Z"
        },
        "id": "D9giVv4z_42_"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "inputs, labels = next(iter(train_dl))\n",
        "resnet = resnet.to(device)\n",
        "inputs, labels = inputs.to(device), labels.to(device)\n",
        "outputs = resnet(inputs)\n",
        "outputs.size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPkcuNZ7_42_"
      },
      "source": [
        "This models provides us with 1000 values, representing the classes which ResNet was trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m596WCT2_42_"
      },
      "source": [
        "Replace last layer with one that predicts the 64 classes.\n",
        "The network weights should be fixed expected for the last layer that is trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7alchbxh_43A",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def train_model(dataloders,\n",
        "                model,\n",
        "                criterion,\n",
        "                optimizer,\n",
        "                scheduler,\n",
        "                num_epochs=1):\n",
        "    # Train the model and evaluate train and test accuracy\n",
        "    # YOUR CODE\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vzD9iRef_43A",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "resnet = models.resnet50(pretrained=True)\n",
        "# freeze all model parameters\n",
        "for param in resnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# add new layer\n",
        "# hint: you can get the number of features\n",
        "# using in_features, e.g resnet.fc.in_features\n",
        "\n",
        "# resnet.fc = ...\n",
        "\n",
        "# resnet = resnet.cuda()\n",
        "\n",
        "# criterion = ...\n",
        "# optimizer = ...\n",
        "# scheduler = ...\n",
        "\n",
        "dloaders = {'train':train_dl, 'valid':valid_dl}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OV3Q2QDg_43A"
      },
      "outputs": [],
      "source": [
        "model = train_model(dloaders, resnet, criterion, optimizer, scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "FCEvPTyc_43A",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "def visualize_model(dataloders, model, num_images=16):\n",
        "    cnt = 0\n",
        "    fig = plt.figure(1, figsize=(16, 16))\n",
        "    grid = ImageGrid(fig, 111, nrows_ncols=(4, 4), axes_pad=0.05)\n",
        "    for i, (inputs, labels) in enumerate(dataloders['valid']):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "        for j in range(inputs.size()[0]):\n",
        "            ax = grid[cnt]\n",
        "            imshow(ax, inputs.cpu().data[j])\n",
        "            ax.text(10, 210, ' Prediction: {}\\n Real Label: {}'.format(preds[j], labels.data[j]),\n",
        "                    color='k', backgroundcolor='w', alpha=0.8)\n",
        "            cnt += 1\n",
        "            if cnt == num_images:\n",
        "                return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlTfl4Hl_43B"
      },
      "outputs": [],
      "source": [
        "visualize_model(dloaders, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_I10c0tI19m"
      },
      "source": [
        "# Task 2: Low-dimensional dogs (4 points)\n",
        "Train a **Conditional CNN Autoencoder** that takes class labels into account. Show examples of interpolations between instances of different classes in a latent space and related representation of images in original space (just the same way we did it during practical session)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe8ibPgIG4YZ"
      },
      "source": [
        "# Task 3: Boosting the quality (2 points)\n",
        "\n",
        "The general objective here is to boost the quality you got on the first step.\n",
        "You can tune one/two more models from `torchvision` or `timm` and stack their predictions **OR** create your own CNN and use the encoder of your Autoencoder from 2nd task **OR** both.\n",
        "\n",
        "Don't forget to compare your models properly, e.g. it's not enough to run them for only a few epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Hx9w2a-Kpeb"
      },
      "source": [
        "Write a comment on model comparison, things and ideas that helped boost the quality, and anything else you would like to share."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}